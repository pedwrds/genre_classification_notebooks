{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 21:05:44.470185: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier as skKerasClassifier\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# import keras.api._v2.keras as keras #noqa\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras import activations\n",
    "# from keras.losses import CategoricalCrossentropy\n",
    "from keras.callbacks import History, EarlyStopping, ModelCheckpoint\n",
    "# from keras import regularizers\n",
    "# import keras.backend as K\n",
    "\n",
    "from genreclassification.utils import get_project_root\n",
    "\n",
    "import dataframe_image as dfi\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mlnn hyperparameter gridsearch\n",
    "\n",
    "### potential parameter to explore\n",
    "* learning rate\n",
    "* batch size\n",
    "* kernel initialiser\n",
    "* maybe activation functions\n",
    "* model optimiser\n",
    "* dropout rate\n",
    "* hidden dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30 = pd.read_csv(\n",
    "    get_project_root() / \"data/features_30_sec.csv\"\n",
    ")\n",
    "\n",
    "df_3 = pd.read_csv(\n",
    "    get_project_root() / \"data/features_3_sec.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features / targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the target labels:\n",
    "df_3_y = df_3[\"label\"]\n",
    "\n",
    "# find the training features:\n",
    "df_3_x = df_3.drop(\n",
    "    columns=[\"filename\", \"length\", \"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test split before scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df_3_x,\n",
    "    df_3_y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMax scaling for the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler((0,1))\n",
    "# scale fetures and get column names\n",
    "scale_cols = x_train.columns\n",
    "x_scaled = scaler.fit_transform(x_train[scale_cols])\n",
    "# retrieve column names for scaled df:\n",
    "x_train_scaled = pd.DataFrame(\n",
    "    x_scaled,\n",
    "    columns=scale_cols\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## mlnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split training set into training and validation\n",
    "### not requred as using cross CV for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_val, y_train, y_val = train_test_split(\n",
    "#     x_train,\n",
    "#     y_train,\n",
    "#     test_size=0.2,\n",
    "#     random_state=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in [(x_train, \"x_train\"), (x_val, \"  x_val\"), (y_train, \"y_train\"), (y_val, \"  y_val\")]:\n",
    "#     print(f\"{d[1]}: {d[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding the categorical classes\n",
    "* the model will produce a probability score for each of the 10 classes, assigning the most likely label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by mapping the labels to numerical values:\n",
    "catno_to_label = {key:value for (key, value) in enumerate(sorted(set(y_train)))}\n",
    "# catno_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse this:\n",
    "label_to_catno = {v:k for k,v in catno_to_label.items()}\n",
    "# label_to_catno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.map(label_to_catno)\n",
    "# y_val = y_val.map(label_to_catno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_as_binary = LabelBinarizer()\n",
    "y_train = label_as_binary.fit_transform(y_train)\n",
    "# y_val = label_as_binary.fit_transform(y_val)\n",
    "# y_val = label_as_binary.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df is easier to handle later in k-folds\n",
    "y_train = pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (7992, 57)\n",
      "y_train: (7992, 10)\n"
     ]
    }
   ],
   "source": [
    "for d in [\n",
    "    (x_train, \"x_train\"),\n",
    "    # (x_val, \"  x_val\"),\n",
    "    (y_train, \"y_train\"),\n",
    "    # (y_val, \"  y_val\")\n",
    "]:\n",
    "    print(f\"{d[1]}: {d[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### define model functions ready for gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlnn(\n",
    "    hidden_dim=128,\n",
    "    activation_fn=activations.selu,\n",
    "    dropout_rate=0.2\n",
    "):\n",
    "    model = Sequential(name=\"mlnn_genre_classification\")\n",
    "    #input layer\n",
    "    model.add(Dense(\n",
    "        units=32,\n",
    "        activation=activation_fn,\n",
    "        # kernel_regularizer=regularizers.l2(0.01),\n",
    "        input_shape=(x_train_scaled.shape[1],),\n",
    "        name=\"input\")\n",
    "    )\n",
    "    # batch normalistion:\n",
    "    model.add(BatchNormalization())\n",
    "    # dropout\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # hidden layer\n",
    "    model.add(Dense(\n",
    "        units=hidden_dim,\n",
    "        activation=activation_fn,\n",
    "        # kernel_regularizer=regularizers.l2(0.01),\n",
    "        name=\"hidden1\"\n",
    "    ))\n",
    "    # batch normalistion:\n",
    "    model.add(BatchNormalization())\n",
    "    # dropout\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # hidden layer\n",
    "    model.add(Dense(\n",
    "        units=hidden_dim,\n",
    "        activation=activation_fn,\n",
    "        # kernel_regularizer=regularizers.l2(0.01),\n",
    "        name=\"hidden2\"\n",
    "    ))\n",
    "    # batch normalistion:\n",
    "    model.add(BatchNormalization())\n",
    "    # dropout\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # hidden layer\n",
    "    model.add(Dense(\n",
    "        units=hidden_dim,\n",
    "        activation=\"selu\",\n",
    "        # kernel_regularizer=regularizers.l2(0.01),\n",
    "        name=\"hidden3\"\n",
    "    ))\n",
    "    # batch normalistion:\n",
    "    model.add(BatchNormalization())\n",
    "    # dropout\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # output layer\n",
    "    model.add(Dense(\n",
    "        units=10,\n",
    "        activation=\"softmax\",\n",
    "        name=\"output\"\n",
    "    ))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlnn_compile(\n",
    "    model,\n",
    "    optimiser=optimizers.Adam,\n",
    "    learning_rate=0.0001\n",
    "):\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=optimiser(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlnn_fit(\n",
    "    model,\n",
    "    x,\n",
    "    y,\n",
    "    val_xy,\n",
    "    epochs=700,\n",
    "    batch_size=32,\n",
    "):\n",
    "    history=History()\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0,\n",
    "        restore_best_weights=True,\n",
    "        patience=epochs,\n",
    "        baseline=None\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x,\n",
    "        y,\n",
    "        validation_data=val_xy,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        callbacks=[\n",
    "            history,\n",
    "            early_stopping\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### function for average metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_metrics(y_test, y_pred):\n",
    "    scorers = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"f1_micro\": f1_score(y_test, y_pred, average=\"micro\"),\n",
    "        \"f1_macro\": f1_score(y_test, y_pred, average=\"macro\"),\n",
    "        \"recall_micro\": recall_score(y_test, y_pred, average=\"micro\"),\n",
    "        \"recall_macro\": recall_score(y_test, y_pred, average=\"macro\"),\n",
    "        \"precision_micro\": precision_score(y_test, y_pred, average=\"micro\"),\n",
    "        \"precision_macro\": precision_score(y_test, y_pred, average=\"macro\")\n",
    "    }\n",
    "    df = pd.DataFrame(index=scorers.keys(), columns=[\"metric score\"])\n",
    "    for scorer in scorers.keys():\n",
    "        df.at[scorer, \"metric score\"] = scorers[scorer]\n",
    "    df=df.transpose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### define parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"hidden_dim\": [64, 128],\n",
    "    # \"activation\": [activations.selu, activations.relu],\n",
    "    # \"kernel_initialiser\": [\"GlorotUniform\"],\n",
    "    \"dropout_rate\": [0.1, 0.2],\n",
    "    # \"optimiser\": [\"Adam\"],\n",
    "    \"learning_rate\": [0.001, 0.0005, 0.0001],\n",
    "    \"batch_size\": [32, 64],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the combinations for params in a list to avoid writing many nested loops:\n",
    "keys, values = zip(*params.items())\n",
    "param_combs = [dict(zip(keys, v)) for v in itertools.product(*values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### custom gridsearchCV\n",
    "* have had to resort to a custom gridsearch loop using 3-fold cross validation due to:\n",
    "    * there being tunable parameters in the build, compile, and fit functions of the mlnn\n",
    "    * handling of the 10 class output and the requirement to translate the encoding\n",
    "* -> split into 5 folds to ensure that there is a good amount of training data in each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_dim': [64, 128],\n",
       " 'dropout_rate': [0.1, 0.2],\n",
       " 'learning_rate': [0.001, 0.0005, 0.0001],\n",
       " 'batch_size': [32, 64]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(param_combs))\n",
    "# param_combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same folds for each parameter grid point:\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "\n",
    "# store the average results of each grid point:\n",
    "gs_results_pickle = get_project_root() / \"output/gs_results.pkl\"\n",
    "if os.path.exists(gs_results_pickle):\n",
    "    gs_results = pd.read_pickle(gs_results_pickle)\n",
    "else:\n",
    "    gs_results = pd.DataFrame(\n",
    "        columns=[\n",
    "            'params', 'accuracy', 'f1_micro', 'f1_macro', 'recall_micro', 'recall_macro',\n",
    "            'precision_micro', 'precision_macro'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# for param_comb in param_combs[:2]:\n",
    "for c, param_comb in enumerate(param_combs):\n",
    "    print(f\"search: {c}\\n{param_comb}\")\n",
    "    hd, dr = param_comb[\"hidden_dim\"], param_comb[\"dropout_rate\"]\n",
    "    lr = param_comb[\"learning_rate\"]\n",
    "    bs = param_comb[\"batch_size\"]\n",
    "\n",
    "    param_results = pd.DataFrame()\n",
    "    i=0\n",
    "    for train, val in kf.split(x_train_scaled):\n",
    "        print(f\"training fold: {i}\")\n",
    "        i+=1\n",
    "        x_train_fold, y_train_fold = x_train_scaled.iloc[train], y_train.iloc[train]\n",
    "        x_val_fold, y_val_fold = x_train_scaled.iloc[val], y_train.iloc[val]\n",
    "        \n",
    "        # train model at grid point for this fold:\n",
    "        model = build_mlnn(\n",
    "            hidden_dim=hd,\n",
    "            dropout_rate=dr\n",
    "        )\n",
    "        model = mlnn_compile(\n",
    "            model,\n",
    "            learning_rate=lr\n",
    "        )\n",
    "        model = mlnn_fit(\n",
    "            model,\n",
    "            x_train_fold,\n",
    "            y_train_fold,\n",
    "            (x_val_fold, y_val_fold),\n",
    "            batch_size=bs,\n",
    "            # reduce num epochs while searching\n",
    "            epochs=300\n",
    "        )\n",
    "        # make prediction on val set for this fold with model from best epoch:\n",
    "        fold_results = pd.DataFrame()\n",
    "\n",
    "        pred = model.predict(\n",
    "            x_val_fold,\n",
    "            verbose=0\n",
    "        )\n",
    "        pred = np.argmax(pred, axis=1)\n",
    "        pred = pd.Series(pred)\n",
    "        pred = pred.map(catno_to_label)\n",
    "\n",
    "        # wrangle y_val:\n",
    "        y_val_fold = np.array(y_val_fold)\n",
    "        y_val_fold = np.argmax(y_val_fold, axis=1)\n",
    "        y_val_fold = pd.Series(y_val_fold).map(catno_to_label)\n",
    "        y_val_fold.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        fold_results = average_metrics(y_val_fold, pred)\n",
    "        param_results = pd.concat([param_results, fold_results])\n",
    "        \n",
    "    # average the scores for these parameters over the folds:\n",
    "    param_results = pd.DataFrame(param_results.mean()).transpose()\n",
    "    param_results[\"params\"] = str(param_comb)\n",
    "    \n",
    "    gs_results = pd.concat([gs_results, param_results])\n",
    "    gs_results.reset_index(drop=True, inplace=True)\n",
    "    # save in case of dead kernel:\n",
    "    gs_results.to_pickle(gs_results_pickle)   \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recall scores from search grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>precision_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'hidden_dim': 64, 'dropout_rate': 0.1, 'learn...</td>\n",
       "      <td>0.883133</td>\n",
       "      <td>0.883133</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.883133</td>\n",
       "      <td>0.883773</td>\n",
       "      <td>0.883133</td>\n",
       "      <td>0.884334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'hidden_dim': 64, 'dropout_rate': 0.1, 'learn...</td>\n",
       "      <td>0.877630</td>\n",
       "      <td>0.877630</td>\n",
       "      <td>0.877656</td>\n",
       "      <td>0.877630</td>\n",
       "      <td>0.878411</td>\n",
       "      <td>0.877630</td>\n",
       "      <td>0.879543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'hidden_dim': 64, 'dropout_rate': 0.1, 'learn...</td>\n",
       "      <td>0.873250</td>\n",
       "      <td>0.873250</td>\n",
       "      <td>0.872539</td>\n",
       "      <td>0.873250</td>\n",
       "      <td>0.873486</td>\n",
       "      <td>0.873250</td>\n",
       "      <td>0.875621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'hidden_dim': 64, 'dropout_rate': 0.1, 'learn...</td>\n",
       "      <td>0.870619</td>\n",
       "      <td>0.870619</td>\n",
       "      <td>0.870545</td>\n",
       "      <td>0.870619</td>\n",
       "      <td>0.870780</td>\n",
       "      <td>0.870619</td>\n",
       "      <td>0.873557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'hidden_dim': 64, 'dropout_rate': 0.1, 'learn...</td>\n",
       "      <td>0.820946</td>\n",
       "      <td>0.820946</td>\n",
       "      <td>0.819868</td>\n",
       "      <td>0.820946</td>\n",
       "      <td>0.821326</td>\n",
       "      <td>0.820946</td>\n",
       "      <td>0.820212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'hidden_dim': 64, 'dropout_rate': 0.1, 'learn...</td>\n",
       "      <td>0.804680</td>\n",
       "      <td>0.804680</td>\n",
       "      <td>0.803206</td>\n",
       "      <td>0.804680</td>\n",
       "      <td>0.805368</td>\n",
       "      <td>0.804680</td>\n",
       "      <td>0.803934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'hidden_dim': 64, 'dropout_rate': 0.2, 'learn...</td>\n",
       "      <td>0.831832</td>\n",
       "      <td>0.831832</td>\n",
       "      <td>0.830589</td>\n",
       "      <td>0.831832</td>\n",
       "      <td>0.832471</td>\n",
       "      <td>0.831832</td>\n",
       "      <td>0.834986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'hidden_dim': 64, 'dropout_rate': 0.2, 'learn...</td>\n",
       "      <td>0.825950</td>\n",
       "      <td>0.825950</td>\n",
       "      <td>0.824845</td>\n",
       "      <td>0.825950</td>\n",
       "      <td>0.827254</td>\n",
       "      <td>0.825950</td>\n",
       "      <td>0.829002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'hidden_dim': 64, 'dropout_rate': 0.2, 'learn...</td>\n",
       "      <td>0.817317</td>\n",
       "      <td>0.817317</td>\n",
       "      <td>0.816293</td>\n",
       "      <td>0.817317</td>\n",
       "      <td>0.818775</td>\n",
       "      <td>0.817317</td>\n",
       "      <td>0.820747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'hidden_dim': 64, 'dropout_rate': 0.2, 'learn...</td>\n",
       "      <td>0.811936</td>\n",
       "      <td>0.811936</td>\n",
       "      <td>0.810923</td>\n",
       "      <td>0.811936</td>\n",
       "      <td>0.812441</td>\n",
       "      <td>0.811936</td>\n",
       "      <td>0.812695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'hidden_dim': 64, 'dropout_rate': 0.2, 'learn...</td>\n",
       "      <td>0.761888</td>\n",
       "      <td>0.761888</td>\n",
       "      <td>0.759590</td>\n",
       "      <td>0.761888</td>\n",
       "      <td>0.763368</td>\n",
       "      <td>0.761888</td>\n",
       "      <td>0.760689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'hidden_dim': 64, 'dropout_rate': 0.2, 'learn...</td>\n",
       "      <td>0.749375</td>\n",
       "      <td>0.749375</td>\n",
       "      <td>0.746965</td>\n",
       "      <td>0.749375</td>\n",
       "      <td>0.750641</td>\n",
       "      <td>0.749375</td>\n",
       "      <td>0.748022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'hidden_dim': 128, 'dropout_rate': 0.1, 'lear...</td>\n",
       "      <td>0.918168</td>\n",
       "      <td>0.918168</td>\n",
       "      <td>0.917783</td>\n",
       "      <td>0.918168</td>\n",
       "      <td>0.918157</td>\n",
       "      <td>0.918168</td>\n",
       "      <td>0.919244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'hidden_dim': 128, 'dropout_rate': 0.1, 'lear...</td>\n",
       "      <td>0.903776</td>\n",
       "      <td>0.903776</td>\n",
       "      <td>0.903227</td>\n",
       "      <td>0.903776</td>\n",
       "      <td>0.904033</td>\n",
       "      <td>0.903776</td>\n",
       "      <td>0.905551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'hidden_dim': 128, 'dropout_rate': 0.1, 'lear...</td>\n",
       "      <td>0.911660</td>\n",
       "      <td>0.911660</td>\n",
       "      <td>0.911802</td>\n",
       "      <td>0.911660</td>\n",
       "      <td>0.912108</td>\n",
       "      <td>0.911660</td>\n",
       "      <td>0.913162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'hidden_dim': 128, 'dropout_rate': 0.1, 'lear...</td>\n",
       "      <td>0.915164</td>\n",
       "      <td>0.915164</td>\n",
       "      <td>0.914830</td>\n",
       "      <td>0.915164</td>\n",
       "      <td>0.915013</td>\n",
       "      <td>0.915164</td>\n",
       "      <td>0.915999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'hidden_dim': 128, 'dropout_rate': 0.1, 'lear...</td>\n",
       "      <td>0.873248</td>\n",
       "      <td>0.873248</td>\n",
       "      <td>0.873147</td>\n",
       "      <td>0.873248</td>\n",
       "      <td>0.873658</td>\n",
       "      <td>0.873248</td>\n",
       "      <td>0.874001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'hidden_dim': 128, 'dropout_rate': 0.1, 'lear...</td>\n",
       "      <td>0.857232</td>\n",
       "      <td>0.857232</td>\n",
       "      <td>0.857081</td>\n",
       "      <td>0.857232</td>\n",
       "      <td>0.857982</td>\n",
       "      <td>0.857232</td>\n",
       "      <td>0.857985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'hidden_dim': 128, 'dropout_rate': 0.2, 'lear...</td>\n",
       "      <td>0.887260</td>\n",
       "      <td>0.887260</td>\n",
       "      <td>0.886828</td>\n",
       "      <td>0.887260</td>\n",
       "      <td>0.887487</td>\n",
       "      <td>0.887260</td>\n",
       "      <td>0.889602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'hidden_dim': 128, 'dropout_rate': 0.2, 'lear...</td>\n",
       "      <td>0.884134</td>\n",
       "      <td>0.884134</td>\n",
       "      <td>0.884248</td>\n",
       "      <td>0.884134</td>\n",
       "      <td>0.884380</td>\n",
       "      <td>0.884134</td>\n",
       "      <td>0.886994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'hidden_dim': 128, 'dropout_rate': 0.2, 'lear...</td>\n",
       "      <td>0.879505</td>\n",
       "      <td>0.879505</td>\n",
       "      <td>0.879528</td>\n",
       "      <td>0.879505</td>\n",
       "      <td>0.880395</td>\n",
       "      <td>0.879505</td>\n",
       "      <td>0.880660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'hidden_dim': 128, 'dropout_rate': 0.2, 'lear...</td>\n",
       "      <td>0.865366</td>\n",
       "      <td>0.865366</td>\n",
       "      <td>0.865231</td>\n",
       "      <td>0.865366</td>\n",
       "      <td>0.865659</td>\n",
       "      <td>0.865366</td>\n",
       "      <td>0.868440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'hidden_dim': 128, 'dropout_rate': 0.2, 'lear...</td>\n",
       "      <td>0.814064</td>\n",
       "      <td>0.814064</td>\n",
       "      <td>0.813207</td>\n",
       "      <td>0.814064</td>\n",
       "      <td>0.814591</td>\n",
       "      <td>0.814064</td>\n",
       "      <td>0.814643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'hidden_dim': 128, 'dropout_rate': 0.2, 'lear...</td>\n",
       "      <td>0.804182</td>\n",
       "      <td>0.804182</td>\n",
       "      <td>0.803100</td>\n",
       "      <td>0.804182</td>\n",
       "      <td>0.804707</td>\n",
       "      <td>0.804182</td>\n",
       "      <td>0.804348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  accuracy  f1_micro  \\\n",
       "0   {'hidden_dim': 64, 'dropout_rate': 0.1, 'learn...  0.883133  0.883133   \n",
       "1   {'hidden_dim': 64, 'dropout_rate': 0.1, 'learn...  0.877630  0.877630   \n",
       "2   {'hidden_dim': 64, 'dropout_rate': 0.1, 'learn...  0.873250  0.873250   \n",
       "3   {'hidden_dim': 64, 'dropout_rate': 0.1, 'learn...  0.870619  0.870619   \n",
       "4   {'hidden_dim': 64, 'dropout_rate': 0.1, 'learn...  0.820946  0.820946   \n",
       "5   {'hidden_dim': 64, 'dropout_rate': 0.1, 'learn...  0.804680  0.804680   \n",
       "6   {'hidden_dim': 64, 'dropout_rate': 0.2, 'learn...  0.831832  0.831832   \n",
       "7   {'hidden_dim': 64, 'dropout_rate': 0.2, 'learn...  0.825950  0.825950   \n",
       "8   {'hidden_dim': 64, 'dropout_rate': 0.2, 'learn...  0.817317  0.817317   \n",
       "9   {'hidden_dim': 64, 'dropout_rate': 0.2, 'learn...  0.811936  0.811936   \n",
       "10  {'hidden_dim': 64, 'dropout_rate': 0.2, 'learn...  0.761888  0.761888   \n",
       "11  {'hidden_dim': 64, 'dropout_rate': 0.2, 'learn...  0.749375  0.749375   \n",
       "12  {'hidden_dim': 128, 'dropout_rate': 0.1, 'lear...  0.918168  0.918168   \n",
       "13  {'hidden_dim': 128, 'dropout_rate': 0.1, 'lear...  0.903776  0.903776   \n",
       "14  {'hidden_dim': 128, 'dropout_rate': 0.1, 'lear...  0.911660  0.911660   \n",
       "15  {'hidden_dim': 128, 'dropout_rate': 0.1, 'lear...  0.915164  0.915164   \n",
       "16  {'hidden_dim': 128, 'dropout_rate': 0.1, 'lear...  0.873248  0.873248   \n",
       "17  {'hidden_dim': 128, 'dropout_rate': 0.1, 'lear...  0.857232  0.857232   \n",
       "18  {'hidden_dim': 128, 'dropout_rate': 0.2, 'lear...  0.887260  0.887260   \n",
       "19  {'hidden_dim': 128, 'dropout_rate': 0.2, 'lear...  0.884134  0.884134   \n",
       "20  {'hidden_dim': 128, 'dropout_rate': 0.2, 'lear...  0.879505  0.879505   \n",
       "21  {'hidden_dim': 128, 'dropout_rate': 0.2, 'lear...  0.865366  0.865366   \n",
       "22  {'hidden_dim': 128, 'dropout_rate': 0.2, 'lear...  0.814064  0.814064   \n",
       "23  {'hidden_dim': 128, 'dropout_rate': 0.2, 'lear...  0.804182  0.804182   \n",
       "\n",
       "    f1_macro  recall_micro  recall_macro  precision_micro  precision_macro  \n",
       "0   0.882759      0.883133      0.883773         0.883133         0.884334  \n",
       "1   0.877656      0.877630      0.878411         0.877630         0.879543  \n",
       "2   0.872539      0.873250      0.873486         0.873250         0.875621  \n",
       "3   0.870545      0.870619      0.870780         0.870619         0.873557  \n",
       "4   0.819868      0.820946      0.821326         0.820946         0.820212  \n",
       "5   0.803206      0.804680      0.805368         0.804680         0.803934  \n",
       "6   0.830589      0.831832      0.832471         0.831832         0.834986  \n",
       "7   0.824845      0.825950      0.827254         0.825950         0.829002  \n",
       "8   0.816293      0.817317      0.818775         0.817317         0.820747  \n",
       "9   0.810923      0.811936      0.812441         0.811936         0.812695  \n",
       "10  0.759590      0.761888      0.763368         0.761888         0.760689  \n",
       "11  0.746965      0.749375      0.750641         0.749375         0.748022  \n",
       "12  0.917783      0.918168      0.918157         0.918168         0.919244  \n",
       "13  0.903227      0.903776      0.904033         0.903776         0.905551  \n",
       "14  0.911802      0.911660      0.912108         0.911660         0.913162  \n",
       "15  0.914830      0.915164      0.915013         0.915164         0.915999  \n",
       "16  0.873147      0.873248      0.873658         0.873248         0.874001  \n",
       "17  0.857081      0.857232      0.857982         0.857232         0.857985  \n",
       "18  0.886828      0.887260      0.887487         0.887260         0.889602  \n",
       "19  0.884248      0.884134      0.884380         0.884134         0.886994  \n",
       "20  0.879528      0.879505      0.880395         0.879505         0.880660  \n",
       "21  0.865231      0.865366      0.865659         0.865366         0.868440  \n",
       "22  0.813207      0.814064      0.814591         0.814064         0.814643  \n",
       "23  0.803100      0.804182      0.804707         0.804182         0.804348  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve scores saved as pickle:\n",
    "gs_results = pd.read_pickle(\n",
    "    get_project_root() / \"output/gs_results_20221217.pkl\"\n",
    ")\n",
    "gs_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>precision_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'hidden_dim': 128, 'dropout_rate': 0.1, 'lear...</td>\n",
       "      <td>0.918168</td>\n",
       "      <td>0.918168</td>\n",
       "      <td>0.917783</td>\n",
       "      <td>0.918168</td>\n",
       "      <td>0.918157</td>\n",
       "      <td>0.918168</td>\n",
       "      <td>0.919244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  accuracy  f1_micro  \\\n",
       "12  {'hidden_dim': 128, 'dropout_rate': 0.1, 'lear...  0.918168  0.918168   \n",
       "\n",
       "    f1_macro  recall_micro  recall_macro  precision_micro  precision_macro  \n",
       "12  0.917783      0.918168      0.918157         0.918168         0.919244  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = gs_results[gs_results[\"accuracy\"] == gs_results[\"accuracy\"].max()]\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'hidden_dim': 128, 'dropout_rate': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = best[\"params\"].reset_index(drop=True)[0]\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* reduced number of epochs while parameter searching -> train model with best params on all training set and test on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.get_config()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('genreclassification-qGJVucn0-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Oct 11 2022, 22:25:13) \n[Clang 12.0.0 (clang-1200.0.32.29)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "071c4954f4b056e381337a2b30bebca67942706fcde46b495279624c5d47332a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
